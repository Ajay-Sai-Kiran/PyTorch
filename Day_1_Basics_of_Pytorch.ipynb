{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day-1 Basics of Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNFXLxVKjX6UtAM3wizyjuK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajay-Sai-Kiran/PyTorch/blob/main/Day_1_Basics_of_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction to PyTorch\n",
        "\n",
        "PyTorch is an open source library developed mainly by **Facebook's artificial**\n",
        "**intelligence research group** as a **Python version of Torch** "
      ],
      "metadata": {
        "id": "LaDRUG2pqKtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It uses the **power of GPUs to speed up the computation of tensors**, which accelerates the training times of complex models."
      ],
      "metadata": {
        "id": "WN4L5LozqzBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPUs in PyTorch"
      ],
      "metadata": {
        "id": "yDTuMdX_q7aJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several platforms that allow the allocation of variables to the GPUs of a\n",
        "machine, with the **Compute Unified Device Architecture (CUDA)** being one of the\n",
        "most commonly used platforms. \n",
        "\n",
        "CUDA is a computing platform developed by Nvidia\n",
        "that speeds up compute-intensive programs thanks to the use of GPUs to perform\n",
        "computations. "
      ],
      "metadata": {
        "id": "t0Db-x2BrC1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, **the allocation of variables to CUDA can be done through the use of the torch.cuda package**"
      ],
      "metadata": {
        "id": "tSURUyHTrOig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "x = torch.Tensor(10).random_(0, 10)\n",
        "x.to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FnbWFDDrfMP",
        "outputId": "0914e630-8a4e-4255-bcff-bbee90288fa6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6., 3., 7., 8., 6., 3., 5., 9., 9., 1.], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To allocate a variable back to the CPU**"
      ],
      "metadata": {
        "id": "R4DJcW5zr51P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.to(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKTEX6KRr4TA",
        "outputId": "11a078ba-8a2a-4e39-be76-3e4051e5063d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6., 3., 7., 8., 6., 3., 5., 9., 9., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " To verify whether **you are able to allocate your variables in CUDA**"
      ],
      "metadata": {
        "id": "nLANYbYcrem3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOKvr15jsSNK",
        "outputId": "f16e3623-db44-48a1-d2da-30c9bc6ae7f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What Are Tensors?"
      ],
      "metadata": {
        "id": "cEAKMyUwrawA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to NumPy, **PyTorch uses tensors to represent data**. "
      ],
      "metadata": {
        "id": "eLK_A5jMsd6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensors are matrix-like structures of n dimensions with the difference being that PyTorch tensors can run on the GPU (while NumPy tensors cannot), which helps to accelerate numerical computations.**"
      ],
      "metadata": {
        "id": "Jg5BAnJBsqVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For tensors, **dimensions** are also known as **ranks**."
      ],
      "metadata": {
        "id": "B9tpT60kssqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Tensors of Different Ranks Using PyTorch"
      ],
      "metadata": {
        "id": "UiJNZee0s0xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code shown here uses a backslash ( \\ ) to split the logic\n",
        "across multiple lines. When the code is executed, Python will ignore the\n",
        "backslash, and treat the code on the next line as a direct continuation of the\n",
        "current line."
      ],
      "metadata": {
        "id": "tfSO8SKVt1Lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 = torch.tensor([0.1,1,0.9,0.7,0.3])\n",
        "tensor_2 = torch.tensor([[0,0.2,0.4,0.6],[1,0.8,0.6,0.4]])\n",
        "tensor_3 = torch.tensor([[[0.3,0.6],[1,0]], \\\n",
        "                         [[0.3,0.6],[0,1]]])"
      ],
      "metadata": {
        "id": "iKDDkfoDtbrv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPU syntax**"
      ],
      "metadata": {
        "id": "7QRwJ43wtVkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 = torch.tensor([0.1,1,0.9,0.7,0.3]).cuda()\n",
        "tensor_2 = torch.tensor([[0,0.2,0.4,0.6], \\\n",
        "                        [1,0.8,0.6,0.4]]).cuda()\n",
        "tensor_3 = torch.tensor([[[0.3,0.6],[1,0]], \\\n",
        "                         [[0.3,0.6],[0,1]]]).cuda()"
      ],
      "metadata": {
        "id": "YZsWWMUUtkqX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor_1.shape)\n",
        "print(tensor_2.shape)\n",
        "print(tensor_3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2OXmxTdtmSP",
        "outputId": "c1ec92e0-41fa-4ff7-afb7-5939ccc8687d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5])\n",
            "torch.Size([2, 4])\n",
            "torch.Size([2, 2, 2])\n"
          ]
        }
      ]
    }
  ]
}